# ğŸ§  j-neural-core

A lightweight Java implementation of a multi-layer perceptron (MLP) neural network â€” from scratch â€” with autograd, training, and examples of classification models built on top of the MLP class.

This project is meant for experimentation with neural networks without using any external ML libraries.

## ğŸ“¦ Features

* Fully custom autograd engine (Value class)
* Multi-Layer Perceptron (MLP) architecture
* Stochastic Gradient Descent (SGD) training loop
* **Automatic switching** between:
  - Binary classification: Sigmoid activation + Binary Cross-Entropy loss
  - Multiclass classification: Softmax activation + Categorical Cross-Entropy loss  
* Binary classification example with simple data
* Digit classification using processed handwritten digit dataset
* Clean Maven-based project structure

## ğŸ“ Folder Structure

```bash
j-neural-core/
â”œâ”€â”€ src/main/
â”‚   â”œâ”€â”€ java/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â””â”€â”€ Main.java               # Entry point to run both classifiers
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ Layer.java
â”‚   â”‚   â”‚   â”œâ”€â”€ MLP.java                # Neural network model
â”‚   â”‚   â”‚   â”œâ”€â”€ Neuron.java
â”‚   â”‚   â”‚   â””â”€â”€ Value.java              # Autograd engine
â”‚   â”‚   â”œâ”€â”€ engine/
â”‚   â”‚   â”‚   â””â”€â”€ Trainer.java            # Trainer class with activation/loss switching logic
â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”‚   â””â”€â”€ DigitDataLoader.java    # Loads and parses digit dataset
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚       â”œâ”€â”€ BinaryClassifier.java   # Binary classification using sigmoid + BCE
â”‚   â”‚       â””â”€â”€ DigitRecognizer.java    # Multiclass digit recognition using softmax + CE
â”‚   â””â”€â”€ resources/data/
â”‚       â”œâ”€â”€ digits_original.txt
â”‚       â”œâ”€â”€ digits_test.csv
â”‚       â””â”€â”€ digits_train.csv
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ pom.xml
```

## ğŸ“Š Dataset

The **DigitRecognizer** model uses the *Optical Recognition of Handwritten Digits* dataset collected by:

**E. Alpaydin, C. Kaynak**  
Department of Computer Engineering  
BoÄŸaziÃ§i University, Istanbul, Turkey  
(July 1998)

Original images are 32Ã—32 bitmaps. For this project, they were **preprocessed into 8Ã—8 matrices** by dividing into 4Ã—4 non-overlapping blocks and **counting the number of active pixels (value 1) in each block**. This produces inputs with integer values between 0â€“16, reducing dimensionality while preserving useful information and adding robustness to small distortions.

The training and testing CSV files are located in `src/main/resources/data/`.

## ğŸš€ Getting Started

### Prerequisites

- Java 17+
- Maven 3.x
- Git (optional)

### Clone the Repo

```bash
git clone http://github.com/samuel-soltys/j-neural-core
cd j-neural-core
```

### Build and run the project (main training demo)

```bash
mvn compile
mvn exec:java -Dexec.mainClass="app.Main"
```

Alternatively, you can run the individual models directly by setting their class as the entry point:

```bash
mvn exec:java -Dexec.mainClass="models.BinaryClassifier"
mvn exec:java -Dexec.mainClass="models.DigitRecognizer"
```

## ğŸ§ª Classification Logic

* **Auto-switching logic** is based on the number of output neurons:
  - If output layer has **1 neuron**, use Sigmoid + Binary Cross-Entropy loss.
  - If output layer has **>1 neurons**, use Softmax + Categorical Cross-Entropy loss.
* Models:
  - `BinaryClassifier`: Predicts binary labels using hidden ReLU layers and sigmoid output.
  - `DigitRecognizer`: Predicts digits (0â€“9) using softmax output with 10 neurons.

## ğŸ“ License

This project is open source and available under the MIT License.

---

Project inspired by [micrograd](https://github.com/karpathy/micrograd) by Andrej Karpathy